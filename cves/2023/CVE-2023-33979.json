{"Modified":"2023-06-01T01:17:00","Published":"2023-05-31T19:15:00","access":{},"assigner":"security-advisories@github.com","cvss":null,"cwe":"Unknown","id":"CVE-2023-33979","impact":{},"last-modified":"2023-06-01T01:17:00","references":["https://github.com/binary-husky/gpt_academic/commit/1dcc2873d2168ad2d3d70afcb453ac1695fbdf02","https://github.com/binary-husky/gpt_academic/security/advisories/GHSA-pg65-p24m-wf5g"],"summary":"gpt_academic provides a graphical interface for ChatGPT/GLM. A vulnerability was found in gpt_academic 3.37 and prior. This issue affects some unknown processing of the component Configuration File Handler. The manipulation of the argument file leads to information disclosure. Since no sensitive files are configured to be off-limits, sensitive information files in some working directories can be read through the `/file` route, leading to sensitive information leakage. This affects users that uses file configurations via `config.py`, `config_private.py`, `Dockerfile`. A patch is available at commit 1dcc2873d2168ad2d3d70afcb453ac1695fbdf02. As a workaround, one may use environment variables instead of `config*.py` files to configure this project, or use docker-compose installation to configure this project.","vulnerable_configuration":[],"vulnerable_configuration_cpe_2_2":[],"vulnerable_product":[]}